{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('abc').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = spark.read.csv('s3://sec-finc/t1/',header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split, explode,col\n",
    "col_names = ['accession_number_int','accession_number','cik','company_name',\n",
    "             'filing_date','document_type','document_period_end_date','current_fiscal_year_end_date',\n",
    "             'document_fiscal_year_focus','document_fiscal_period_focus','current_fiscal_year_end_month',\n",
    "             'amendment_flag','assigned_sic','irs_number','state_of_incorporation','mailing_address_street1',\n",
    "             'mailing_address_street2','mailing_address_city','mailing_address_state','mailing_address_zip',\n",
    "             'business_address_street1','business_address_street2','business_address_city','business_address_state',\n",
    "             'business_address_zip','mailing_phone_number','business_phone_number']\n",
    "for i in range(0,len(col_names)):\n",
    "    df1 = df1.withColumn(col_names[i], split(col(\"_c0\"), \"\\t\")[i]).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('s3://sec-finc/annual_statement_data_v2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o220.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 3.0 failed 4 times, most recent failure: Lost task 0.3 in stage 3.0 (TID 15, ip-172-31-30-145.ec2.internal, executor 5): java.io.FileNotFoundException: No such file or directory 's3://sec-finc/annual_statement_data_v1/20200329_061640_00005_6ncbd_5feb3727-2934-409f-878c-32fad57257ba'\nIt is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:160)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:211)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:130)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:291)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:283)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:836)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:836)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:2041)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2029)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2028)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2028)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:966)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:966)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:966)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2262)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2211)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2200)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:777)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:401)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3389)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2550)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2550)\n\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3370)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:84)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:165)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:74)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3369)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2550)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2764)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:254)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:291)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.io.FileNotFoundException: No such file or directory 's3://sec-finc/annual_statement_data_v1/20200329_061640_00005_6ncbd_5feb3727-2934-409f-878c-32fad57257ba'\nIt is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:160)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:211)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:130)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:291)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:283)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:836)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:836)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-1a6ce2362cd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    378\u001b[0m         \"\"\"\n\u001b[1;32m    379\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o220.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 3.0 failed 4 times, most recent failure: Lost task 0.3 in stage 3.0 (TID 15, ip-172-31-30-145.ec2.internal, executor 5): java.io.FileNotFoundException: No such file or directory 's3://sec-finc/annual_statement_data_v1/20200329_061640_00005_6ncbd_5feb3727-2934-409f-878c-32fad57257ba'\nIt is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:160)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:211)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:130)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:291)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:283)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:836)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:836)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:2041)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2029)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2028)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2028)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:966)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:966)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:966)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2262)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2211)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2200)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:777)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:401)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3389)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2550)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2550)\n\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3370)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:84)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:165)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:74)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3369)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2550)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2764)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:254)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:291)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.io.FileNotFoundException: No such file or directory 's3://sec-finc/annual_statement_data_v1/20200329_061640_00005_6ncbd_5feb3727-2934-409f-878c-32fad57257ba'\nIt is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:160)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:211)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:130)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:291)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:283)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:836)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:836)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPLORATION of df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = spark.read.csv('s3://sec-finc/t1/',header = False)\n",
    "df2 = spark.read.csv('s3://sec-finc/t2/',header = False)\n",
    "df3 = spark.read.csv('s3://sec-finc/t3/',header = False)\n",
    "df4 = spark.read.csv('s3://sec-finc/t4/',header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------+--------------------+-----------+-------------+------------------------+----------------------------+--------------------------+----------------------------+-----------------------------+--------------+------------+----------+----------------------+-----------------------+-----------------------+--------------------+---------------------+-------------------+------------------------+------------------------+---------------------+----------------------+--------------------+--------------------+---------------------+\n",
      "|accession_number_int|    accession_number|    cik|        company_name|filing_date|document_type|document_period_end_date|current_fiscal_year_end_date|document_fiscal_year_focus|document_fiscal_period_focus|current_fiscal_year_end_month|amendment_flag|assigned_sic|irs_number|state_of_incorporation|mailing_address_street1|mailing_address_street2|mailing_address_city|mailing_address_state|mailing_address_zip|business_address_street1|business_address_street2|business_address_city|business_address_state|business_address_zip|mailing_phone_number|business_phone_number|\n",
      "+--------------------+--------------------+-------+--------------------+-----------+-------------+------------------------+----------------------------+--------------------------+----------------------------+-----------------------------+--------------+------------+----------+----------------------+-----------------------+-----------------------+--------------------+---------------------+-------------------+------------------------+------------------------+---------------------+----------------------+--------------------+--------------------+---------------------+\n",
      "|     147793216011396|0001477932-16-011396|1528697|     BOOKEDBYUS INC.| 2016-07-15|         10-Q|              2016-05-31|                     --08-31|                      2016|                          Q3|                            8|         false|        5045|261679929 |                    NV|   619 S. RIDGELEY D...|                     \\N|         LOS ANGELES|                   CA|              90036|    619 S. RIDGELEY D...|                      \\N|          LOS ANGELES|                    CA|               90036|                  \\N|         (323) 634-10|\n",
      "|     147793216011552|0001477932-16-011552|1532926|                 BRK|       null|         null|                    null|                        null|                      null|                        null|                         null|          null|        null|      null|                  null|                   null|                   null|                null|                 null|               null|                    null|                    null|                 null|                  null|                null|                null|                 null|\n",
      "|     147793216012172|0001477932-16-012172|1317839| UMATRIN HOLDING LTD| 2016-08-22|         10-Q|              2016-06-30|                     --12-31|                      2016|                          Q2|                           12|         false|        7389|870814235 |                    \\N|                  NO.32|                   null|                null|                 null|               null|                    null|                    null|                 null|                  null|                null|                null|                 null|\n",
      "|     147793216012878|0001477932-16-012878|1639234|              T-BAMM| 2016-10-11|         10-Q|              2016-08-31|                     --02-28|                      2017|                          Q2|                            2|         false|        5651|473176820 |                    NV|   112 NORTH CURRY S...|                     \\N|         CARSON CITY|                   NV|              89703|    112 NORTH CURRY S...|                      \\N|          CARSON CITY|                    NV|               89703|                  \\N|         888-297-9207|\n",
      "|     147793216013334|0001477932-16-013334|1537528|              ZOSANO|       null|         null|                    null|                        null|                      null|                        null|                         null|          null|        null|      null|                  null|                   null|                   null|                null|                 null|               null|                    null|                    null|                 null|                  null|                null|                null|                 null|\n",
      "|     147793216013650|0001477932-16-013650|1388486|SPOTLIGHT INNOVATION|       null|         null|                    null|                        null|                      null|                        null|                         null|          null|        null|      null|                  null|                   null|                   null|                null|                 null|               null|                    null|                    null|                 null|                  null|                null|                null|                 null|\n",
      "|     147793216013919|0001477932-16-013919|1528697|     BOOKEDBYUS INC.| 2016-12-05|         10-K|              2016-08-31|                     --08-31|                      2016|                          FY|                            8|         false|        5045|261679929 |                    NV|   619 S. RIDGELEY D...|                     \\N|         LOS ANGELES|                   CA|              90036|    619 S. RIDGELEY D...|                      \\N|          LOS ANGELES|                    CA|               90036|                  \\N|         (323) 634-10|\n",
      "|     147793217000195|0001477932-17-000195|1687065|    KOKOS GROUP INC.| 2017-01-13|         10-Q|              2016-11-30|                     --08-31|                      2017|                          Q1|                            8|         false|        2086|813433108 |                    NV|   121 SW SALMON STREET|             SUITE 1100|            PORTLAND|                   OR|              97204|    121 SW SALMON STREET|              SUITE 1100|             PORTLAND|                    OR|               97204|                  \\N|         503-471-1332|\n",
      "|     147793217000472|0001477932-17-000472|1624140|PARAMOUNT SUPPLY INC| 2017-01-31|         10-Q|              2016-12-31|                     --09-30|                      2017|                          Q1|                            9|         false|        3100|352515740 |                    NV|   40 LIELAIS PROSPEKTS|                     \\N|           VENTSPILS|                   1R|            LV-3601|    40 LIELAIS PROSPEKTS|                      \\N|            VENTSPILS|                    1R|             LV-3601|                  \\N|         702-509-1266|\n",
      "|     147793217000749|0001477932-17-000749|1520118|            EMS FIND|       null|         null|                    null|                        null|                      null|                        null|                         null|          null|        null|      null|                  null|                   null|                   null|                null|                 null|               null|                    null|                    null|                 null|                  null|                null|                null|                 null|\n",
      "|     147793217000776|0001477932-17-000776|1546853|SKKYNET CLOUD SYS...|       null|         null|                    null|                        null|                      null|                        null|                         null|          null|        null|      null|                  null|                   null|                   null|                null|                 null|               null|                    null|                    null|                 null|                  null|                null|                null|                 null|\n",
      "|     147793217001513|0001477932-17-001513|1487931|         FISION CORP| 2017-04-03|       10-K/A|              2016-12-31|                     --12-31|                      2016|                          FY|                           12|         false|        6770|272205792 |                    \\N|   430 FIRST AVENUE ...|              SUITE 620|         MINNEAPOLIS|                   MN|              55401|    430 FIRST AVENUE ...|               SUITE 620|          MINNEAPOLIS|                    MN|               55401|                  \\N|         612-927-3700|\n",
      "|     147793217001669|0001477932-17-001669|1402371|     ELRAY RESOURCES|       null|         null|                    null|                        null|                      null|                        null|                         null|          null|        null|      null|                  null|                   null|                   null|                null|                 null|               null|                    null|                    null|                 null|                  null|                null|                null|                 null|\n",
      "|     147793217001708|0001477932-17-001708|1443863|       BIOCORRX INC.| 2017-04-13|         10-K|              2016-12-31|                     --12-31|                      2016|                          FY|                           12|         false|        8093|900967447 |                    \\N|   2390 EAST ORANGEW...|              SUITE 575|             ANAHEIM|                   CA|              92806|    2390 EAST ORANGEW...|               SUITE 575|              ANAHEIM|                    CA|               92806|                  \\N|         (714) 462-48|\n",
      "|     147793217001790|0001477932-17-001790|1125699|  DAIS ANALYTIC CORP| 2017-04-17|         10-K|              2016-12-31|                     --12-31|                      2016|                          FY|                           12|         false|        3990|141760865 |                    NY|   11552 PROSPEROUS ...|                     \\N|              ODESSA|                   FL|             335566|    11552 PROSPEROUS ...|                      \\N|               ODESSA|                    FL|               33556|                  \\N|         (727) 375-84|\n",
      "|     147793217002410|0001477932-17-002410|1643319|SLEEPAID HOLDING CO.| 2017-05-19|         10-Q|              2017-03-31|                     --12-31|                      2017|                          Q1|                           12|         false|        5020|473785730 |                    NV|   RM 10 1/F WELLBOR...|                     \\N|           HONG KONG|                   F4|                 \\N|    RM 10 1/F WELLBOR...|                      \\N|            HONG KONG|                    F4|                  \\N|                  \\N|         (852) 280623|\n",
      "|     147793217002414|0001477932-17-002414| 936446|PRECISION AEROSPA...|       null|         null|                    null|                        null|                      null|                        null|                         null|          null|        null|      null|                  null|                   null|                   null|                null|                 null|               null|                    null|                    null|                 null|                  null|                null|                null|                 null|\n",
      "|     147793217002566|0001477932-17-002566|1619096|SUMMIT NETWORKS INC.| 2017-05-26|       10-K/A|              2016-07-31|                     --07-31|                      2016|                          FY|                            7|          true|        3231|352511257 |                    NV|     JAUNCIEMA GATVE 40|         ZIEMELU RAJONS|                RIGA|                   1R|            LV-1023|      JAUNCIEMA GATVE 40|          ZIEMELU RAJONS|                 RIGA|                    1R|             LV-1023|                  \\N|         775-572-8824|\n",
      "|     147793217002839|0001477932-17-002839| 859747|      1PM INDUSTRIES| 2017-06-14|         10-K|              2017-02-28|                     --02-28|                      2017|                          FY|                            2|         false|        2000|473278534 |                    \\N|    312 S BEVERLY DRIVE|                  #3401|       BEVERLY HILLS|                   CA|              90212|     312 S BEVERLY DRIVE|                   #3401|        BEVERLY HILLS|                    CA|               90212|                  \\N|         424-253-9991|\n",
      "|     147793217003607|0001477932-17-003607|1438673|      EVERGREEN-AGRA|       null|         null|                    null|                        null|                      null|                        null|                         null|          null|        null|      null|                  null|                   null|                   null|                null|                 null|               null|                    null|                    null|                 null|                  null|                null|                null|                 null|\n",
      "+--------------------+--------------------+-------+--------------------+-----------+-------------+------------------------+----------------------------+--------------------------+----------------------------+-----------------------------+--------------+------------+----------+----------------------+-----------------------+-----------------------+--------------------+---------------------+-------------------+------------------------+------------------------+---------------------+----------------------+--------------------+--------------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split, explode,col\n",
    "col_names = ['accession_number_int','accession_number','cik','company_name',\n",
    "             'filing_date','document_type','document_period_end_date','current_fiscal_year_end_date',\n",
    "             'document_fiscal_year_focus','document_fiscal_period_focus','current_fiscal_year_end_month',\n",
    "             'amendment_flag','assigned_sic','irs_number','state_of_incorporation','mailing_address_street1',\n",
    "             'mailing_address_street2','mailing_address_city','mailing_address_state','mailing_address_zip',\n",
    "             'business_address_street1','business_address_street2','business_address_city','business_address_state',\n",
    "             'business_address_zip','mailing_phone_number','business_phone_number']\n",
    "for i in range(0,len(col_names)):\n",
    "    df1 = df1.withColumn(col_names[i], split(col(\"_c0\"), \"\\t\")[i]).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------+--------------------+-----------+-------------+------------------------+----------------------------+--------------------------+----------------------------+-----------------------------+--------------+------------+----------+----------------------+-----------------------+-----------------------+--------------------+---------------------+-------------------+------------------------+------------------------+---------------------+----------------------+--------------------+--------------------+---------------------+\n",
      "|accession_number_int|    accession_number|    cik|        company_name|filing_date|document_type|document_period_end_date|current_fiscal_year_end_date|document_fiscal_year_focus|document_fiscal_period_focus|current_fiscal_year_end_month|amendment_flag|assigned_sic|irs_number|state_of_incorporation|mailing_address_street1|mailing_address_street2|mailing_address_city|mailing_address_state|mailing_address_zip|business_address_street1|business_address_street2|business_address_city|business_address_state|business_address_zip|mailing_phone_number|business_phone_number|\n",
      "+--------------------+--------------------+-------+--------------------+-----------+-------------+------------------------+----------------------------+--------------------------+----------------------------+-----------------------------+--------------+------------+----------+----------------------+-----------------------+-----------------------+--------------------+---------------------+-------------------+------------------------+------------------------+---------------------+----------------------+--------------------+--------------------+---------------------+\n",
      "|     147793216011396|0001477932-16-011396|1528697|     BOOKEDBYUS INC.| 2016-07-15|         10-Q|              2016-05-31|                     --08-31|                      2016|                          Q3|                            8|         false|        5045|261679929 |                    NV|   619 S. RIDGELEY D...|                     \\N|         LOS ANGELES|                   CA|              90036|    619 S. RIDGELEY D...|                      \\N|          LOS ANGELES|                    CA|               90036|                  \\N|         (323) 634-10|\n",
      "|     147793216011552|0001477932-16-011552|1532926|                 BRK|       null|         null|                    null|                        null|                      null|                        null|                         null|          null|        null|      null|                  null|                   null|                   null|                null|                 null|               null|                    null|                    null|                 null|                  null|                null|                null|                 null|\n",
      "|     147793216012172|0001477932-16-012172|1317839| UMATRIN HOLDING LTD| 2016-08-22|         10-Q|              2016-06-30|                     --12-31|                      2016|                          Q2|                           12|         false|        7389|870814235 |                    \\N|                  NO.32|                   null|                null|                 null|               null|                    null|                    null|                 null|                  null|                null|                null|                 null|\n",
      "|     147793216012878|0001477932-16-012878|1639234|              T-BAMM| 2016-10-11|         10-Q|              2016-08-31|                     --02-28|                      2017|                          Q2|                            2|         false|        5651|473176820 |                    NV|   112 NORTH CURRY S...|                     \\N|         CARSON CITY|                   NV|              89703|    112 NORTH CURRY S...|                      \\N|          CARSON CITY|                    NV|               89703|                  \\N|         888-297-9207|\n",
      "|     147793216013334|0001477932-16-013334|1537528|              ZOSANO|       null|         null|                    null|                        null|                      null|                        null|                         null|          null|        null|      null|                  null|                   null|                   null|                null|                 null|               null|                    null|                    null|                 null|                  null|                null|                null|                 null|\n",
      "|     147793216013650|0001477932-16-013650|1388486|SPOTLIGHT INNOVATION|       null|         null|                    null|                        null|                      null|                        null|                         null|          null|        null|      null|                  null|                   null|                   null|                null|                 null|               null|                    null|                    null|                 null|                  null|                null|                null|                 null|\n",
      "|     147793216013919|0001477932-16-013919|1528697|     BOOKEDBYUS INC.| 2016-12-05|         10-K|              2016-08-31|                     --08-31|                      2016|                          FY|                            8|         false|        5045|261679929 |                    NV|   619 S. RIDGELEY D...|                     \\N|         LOS ANGELES|                   CA|              90036|    619 S. RIDGELEY D...|                      \\N|          LOS ANGELES|                    CA|               90036|                  \\N|         (323) 634-10|\n",
      "|     147793217000195|0001477932-17-000195|1687065|    KOKOS GROUP INC.| 2017-01-13|         10-Q|              2016-11-30|                     --08-31|                      2017|                          Q1|                            8|         false|        2086|813433108 |                    NV|   121 SW SALMON STREET|             SUITE 1100|            PORTLAND|                   OR|              97204|    121 SW SALMON STREET|              SUITE 1100|             PORTLAND|                    OR|               97204|                  \\N|         503-471-1332|\n",
      "|     147793217000472|0001477932-17-000472|1624140|PARAMOUNT SUPPLY INC| 2017-01-31|         10-Q|              2016-12-31|                     --09-30|                      2017|                          Q1|                            9|         false|        3100|352515740 |                    NV|   40 LIELAIS PROSPEKTS|                     \\N|           VENTSPILS|                   1R|            LV-3601|    40 LIELAIS PROSPEKTS|                      \\N|            VENTSPILS|                    1R|             LV-3601|                  \\N|         702-509-1266|\n",
      "|     147793217000749|0001477932-17-000749|1520118|            EMS FIND|       null|         null|                    null|                        null|                      null|                        null|                         null|          null|        null|      null|                  null|                   null|                   null|                null|                 null|               null|                    null|                    null|                 null|                  null|                null|                null|                 null|\n",
      "|     147793217000776|0001477932-17-000776|1546853|SKKYNET CLOUD SYS...|       null|         null|                    null|                        null|                      null|                        null|                         null|          null|        null|      null|                  null|                   null|                   null|                null|                 null|               null|                    null|                    null|                 null|                  null|                null|                null|                 null|\n",
      "|     147793217001513|0001477932-17-001513|1487931|         FISION CORP| 2017-04-03|       10-K/A|              2016-12-31|                     --12-31|                      2016|                          FY|                           12|         false|        6770|272205792 |                    \\N|   430 FIRST AVENUE ...|              SUITE 620|         MINNEAPOLIS|                   MN|              55401|    430 FIRST AVENUE ...|               SUITE 620|          MINNEAPOLIS|                    MN|               55401|                  \\N|         612-927-3700|\n",
      "|     147793217001669|0001477932-17-001669|1402371|     ELRAY RESOURCES|       null|         null|                    null|                        null|                      null|                        null|                         null|          null|        null|      null|                  null|                   null|                   null|                null|                 null|               null|                    null|                    null|                 null|                  null|                null|                null|                 null|\n",
      "|     147793217001708|0001477932-17-001708|1443863|       BIOCORRX INC.| 2017-04-13|         10-K|              2016-12-31|                     --12-31|                      2016|                          FY|                           12|         false|        8093|900967447 |                    \\N|   2390 EAST ORANGEW...|              SUITE 575|             ANAHEIM|                   CA|              92806|    2390 EAST ORANGEW...|               SUITE 575|              ANAHEIM|                    CA|               92806|                  \\N|         (714) 462-48|\n",
      "|     147793217001790|0001477932-17-001790|1125699|  DAIS ANALYTIC CORP| 2017-04-17|         10-K|              2016-12-31|                     --12-31|                      2016|                          FY|                           12|         false|        3990|141760865 |                    NY|   11552 PROSPEROUS ...|                     \\N|              ODESSA|                   FL|             335566|    11552 PROSPEROUS ...|                      \\N|               ODESSA|                    FL|               33556|                  \\N|         (727) 375-84|\n",
      "|     147793217002410|0001477932-17-002410|1643319|SLEEPAID HOLDING CO.| 2017-05-19|         10-Q|              2017-03-31|                     --12-31|                      2017|                          Q1|                           12|         false|        5020|473785730 |                    NV|   RM 10 1/F WELLBOR...|                     \\N|           HONG KONG|                   F4|                 \\N|    RM 10 1/F WELLBOR...|                      \\N|            HONG KONG|                    F4|                  \\N|                  \\N|         (852) 280623|\n",
      "|     147793217002414|0001477932-17-002414| 936446|PRECISION AEROSPA...|       null|         null|                    null|                        null|                      null|                        null|                         null|          null|        null|      null|                  null|                   null|                   null|                null|                 null|               null|                    null|                    null|                 null|                  null|                null|                null|                 null|\n",
      "|     147793217002566|0001477932-17-002566|1619096|SUMMIT NETWORKS INC.| 2017-05-26|       10-K/A|              2016-07-31|                     --07-31|                      2016|                          FY|                            7|          true|        3231|352511257 |                    NV|     JAUNCIEMA GATVE 40|         ZIEMELU RAJONS|                RIGA|                   1R|            LV-1023|      JAUNCIEMA GATVE 40|          ZIEMELU RAJONS|                 RIGA|                    1R|             LV-1023|                  \\N|         775-572-8824|\n",
      "|     147793217002839|0001477932-17-002839| 859747|      1PM INDUSTRIES| 2017-06-14|         10-K|              2017-02-28|                     --02-28|                      2017|                          FY|                            2|         false|        2000|473278534 |                    \\N|    312 S BEVERLY DRIVE|                  #3401|       BEVERLY HILLS|                   CA|              90212|     312 S BEVERLY DRIVE|                   #3401|        BEVERLY HILLS|                    CA|               90212|                  \\N|         424-253-9991|\n",
      "|     147793217003607|0001477932-17-003607|1438673|      EVERGREEN-AGRA|       null|         null|                    null|                        null|                      null|                        null|                         null|          null|        null|      null|                  null|                   null|                   null|                null|                 null|               null|                    null|                    null|                 null|                  null|                null|                null|                 null|\n",
      "+--------------------+--------------------+-------+--------------------+-----------+-------------+------------------------+----------------------------+--------------------------+----------------------------+-----------------------------+--------------+------------+----------+----------------------+-----------------------+-----------------------+--------------------+---------------------+-------------------+------------------------+------------------------+---------------------+----------------------+--------------------+--------------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = df1.drop('_c0')\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                 _c0|\n",
      "+--------------------+\n",
      "|702325\t7023251700...|\n",
      "|702325\t7023251700...|\n",
      "|39368\t14377491701...|\n",
      "|702325\t7023251700...|\n",
      "|39368\t14377491701...|\n",
      "|1008586\t162828016...|\n",
      "|1008586\t162828016...|\n",
      "|1326089\t155837018...|\n",
      "|1326089\t155837018...|\n",
      "|1326089\t155837018...|\n",
      "|1681903\t168190318...|\n",
      "|1272830\t127283017...|\n",
      "|1272830\t127283017...|\n",
      "|1681903\t168190318...|\n",
      "|1681903\t168190318...|\n",
      "|1681903\t168190318...|\n",
      "|1326089\t155837018...|\n",
      "|1681903\t168190318...|\n",
      "|1326089\t155837018...|\n",
      "|1503636\t144530513...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split, explode,col\n",
    "col_names2 = ['cik','accession_number_int','filing_date','datapoint_id','datapoint_name','version',\n",
    "              'segment_label','segment_hash','start_date','end_date','period_month','string_value','numeric_value',\n",
    "              'decimals','unit','footnotes']\n",
    "for i in range(0,len(col_names2)):\n",
    "    df3 = df3.withColumn(col_names2[i], split(col(\"_c0\"), \"\\t\")[i]).cache()\n",
    "df3 = df3.drop('_c0')\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyspark.sql.functions import split, explode,col\n",
    "col_names1 = ['cik','filing_date','accession_number_int','section_sequence_id','statement_type','report_section_description']\n",
    "for i in range(0,len(col_names1)):\n",
    "    df2 = df2.withColumn(col_names1[i], split(col(\"_c0\"), \"\\t\")[i]).cache()\n",
    "df2 = df2.drop('_c0')\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyspark.sql.functions import split, explode,col\n",
    "col_names3 = ['parent_datapoint_name','datapoint_label','end_date','start_date','period_month','string_value']\n",
    "for i in range(0,len(col_names3)):\n",
    "    df4 = df4.withColumn(col_names3[i], split(col(\"_c0\"), \"\\t\")[i]).cache()\n",
    "df4 = df4.drop('_c0')\n",
    "df4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(accession_number_int='147793216011396', accession_number='0001477932-16-011396', cik='1528697', company_name='BOOKEDBYUS INC.', filing_date='2016-07-15', document_type='10-Q', document_period_end_date='2016-05-31', current_fiscal_year_end_date='--08-31', document_fiscal_year_focus='2016', document_fiscal_period_focus='Q3', current_fiscal_year_end_month='8', amendment_flag='false', assigned_sic='5045', irs_number='261679929 ', state_of_incorporation='NV', mailing_address_street1='619 S. RIDGELEY DRIVE', mailing_address_street2='\\\\N', mailing_address_city='LOS ANGELES', mailing_address_state='CA', mailing_address_zip='90036', business_address_street1='619 S. RIDGELEY DRIVE', business_address_street2='\\\\N', business_address_city='LOS ANGELES', business_address_state='CA', business_address_zip='90036', mailing_phone_number='\\\\N', business_phone_number='(323) 634-10'),\n",
       " Row(accession_number_int='147793216011552', accession_number='0001477932-16-011552', cik='1532926', company_name='BRK', filing_date=None, document_type=None, document_period_end_date=None, current_fiscal_year_end_date=None, document_fiscal_year_focus=None, document_fiscal_period_focus=None, current_fiscal_year_end_month=None, amendment_flag=None, assigned_sic=None, irs_number=None, state_of_incorporation=None, mailing_address_street1=None, mailing_address_street2=None, mailing_address_city=None, mailing_address_state=None, mailing_address_zip=None, business_address_street1=None, business_address_street2=None, business_address_city=None, business_address_state=None, business_address_zip=None, mailing_phone_number=None, business_phone_number=None),\n",
       " Row(accession_number_int='147793216012172', accession_number='0001477932-16-012172', cik='1317839', company_name='UMATRIN HOLDING LTD', filing_date='2016-08-22', document_type='10-Q', document_period_end_date='2016-06-30', current_fiscal_year_end_date='--12-31', document_fiscal_year_focus='2016', document_fiscal_period_focus='Q2', current_fiscal_year_end_month='12', amendment_flag='false', assigned_sic='7389', irs_number='870814235 ', state_of_incorporation='\\\\N', mailing_address_street1='NO.32', mailing_address_street2=None, mailing_address_city=None, mailing_address_state=None, mailing_address_zip=None, business_address_street1=None, business_address_street2=None, business_address_city=None, business_address_state=None, business_address_zip=None, mailing_phone_number=None, business_phone_number=None),\n",
       " Row(accession_number_int='147793216012878', accession_number='0001477932-16-012878', cik='1639234', company_name='T-BAMM', filing_date='2016-10-11', document_type='10-Q', document_period_end_date='2016-08-31', current_fiscal_year_end_date='--02-28', document_fiscal_year_focus='2017', document_fiscal_period_focus='Q2', current_fiscal_year_end_month='2', amendment_flag='false', assigned_sic='5651', irs_number='473176820 ', state_of_incorporation='NV', mailing_address_street1='112 NORTH CURRY STREET', mailing_address_street2='\\\\N', mailing_address_city='CARSON CITY', mailing_address_state='NV', mailing_address_zip='89703', business_address_street1='112 NORTH CURRY STREET', business_address_street2='\\\\N', business_address_city='CARSON CITY', business_address_state='NV', business_address_zip='89703', mailing_phone_number='\\\\N', business_phone_number='888-297-9207'),\n",
       " Row(accession_number_int='147793216013334', accession_number='0001477932-16-013334', cik='1537528', company_name='ZOSANO', filing_date=None, document_type=None, document_period_end_date=None, current_fiscal_year_end_date=None, document_fiscal_year_focus=None, document_fiscal_period_focus=None, current_fiscal_year_end_month=None, amendment_flag=None, assigned_sic=None, irs_number=None, state_of_incorporation=None, mailing_address_street1=None, mailing_address_street2=None, mailing_address_city=None, mailing_address_state=None, mailing_address_zip=None, business_address_street1=None, business_address_street2=None, business_address_city=None, business_address_state=None, business_address_zip=None, mailing_phone_number=None, business_phone_number=None)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.createOrReplaceTempView('company_submission')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+\n",
      "|count(DISTINCT company_name)|\n",
      "+----------------------------+\n",
      "|                       15807|\n",
      "+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## number of companies:\n",
    "spark.sql('''\n",
    "    SELECT count(distinct a.company_name)\n",
    "    FROM company_submission as a\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----+\n",
      "|document_type| cnt|\n",
      "+-------------+----+\n",
      "|         10-Q|9318|\n",
      "|         10-K|8423|\n",
      "|         null|5330|\n",
      "|       10-Q/A|3103|\n",
      "|       10-K/A|1558|\n",
      "|         20-F| 847|\n",
      "|       20-F/A| 338|\n",
      "|         40-F| 149|\n",
      "|        10-KT| 124|\n",
      "|       40-F/A|  33|\n",
      "|        10-QT|  27|\n",
      "|      10-KT/A|  11|\n",
      "|        424B3|   6|\n",
      "|     10-12G/A|   3|\n",
      "|      10-QT/A|   3|\n",
      "|      DEF 14A|   1|\n",
      "|         10-D|   1|\n",
      "|       10-12G|   1|\n",
      "+-------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## type of doc\n",
    "spark.sql('''\n",
    "    SELECT a.document_type,count(distinct a.company_name) as cnt\n",
    "    FROM company_submission as a\n",
    "    group by a.document_type\n",
    "    order by cnt DESC\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+----+\n",
      "|document_fiscal_year_focus| cnt|\n",
      "+--------------------------+----+\n",
      "|                        \\N| 389|\n",
      "|                     43465|   1|\n",
      "|                      2107|   1|\n",
      "|                      2020|   1|\n",
      "|                      2019| 394|\n",
      "|                      2018|3736|\n",
      "|                      2017|3955|\n",
      "|                      2016|4135|\n",
      "|                      2015|4410|\n",
      "|                      2014|4707|\n",
      "|                      2013|4923|\n",
      "|                      2012|5082|\n",
      "|                      2011|4630|\n",
      "|                      2010|1135|\n",
      "|                      2009|   3|\n",
      "|                      2001|   1|\n",
      "+--------------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 10-K yearly submission\n",
    "spark.sql('''\n",
    "    SELECT a.document_fiscal_year_focus,count(distinct a.company_name) as cnt\n",
    "    FROM company_submission as a\n",
    "    WHERE document_type == '10-K'\n",
    "    group by a.document_fiscal_year_focus\n",
    "    order by a.document_fiscal_year_focus DESC\n",
    "''').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "***data cleaning***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPLORATION of df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = spark.read.text('s3://sec-finc/t3/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|702325\t7023251700...|\n",
      "|702325\t7023251700...|\n",
      "|39368\t14377491701...|\n",
      "|702325\t7023251700...|\n",
      "|39368\t14377491701...|\n",
      "|1008586\t162828016...|\n",
      "|1008586\t162828016...|\n",
      "|1326089\t155837018...|\n",
      "|1326089\t155837018...|\n",
      "|1326089\t155837018...|\n",
      "|1681903\t168190318...|\n",
      "|1272830\t127283017...|\n",
      "|1272830\t127283017...|\n",
      "|1681903\t168190318...|\n",
      "|1681903\t168190318...|\n",
      "|1681903\t168190318...|\n",
      "|1326089\t155837018...|\n",
      "|1681903\t168190318...|\n",
      "|1326089\t155837018...|\n",
      "|1503636\t144530513...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split, explode,col\n",
    "col_names2 = ['cik','accession_number_int','filing_date','datapoint_id','datapoint_name','version',\n",
    "              'segment_label','segment_hash','start_date','end_date','period_month','string_value','numeric_value',\n",
    "              'decimals','unit','footnotes']\n",
    "for i in range(0,len(col_names2)):\n",
    "    df3 = df3.withColumn(col_names2[i], split(col(\"value\"), \"\\t\")[i]).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3.drop('value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-22bb2fff2002>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    378\u001b[0m         \"\"\"\n\u001b[1;32m    379\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1257\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.createOrReplaceTempView('data_point')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-----------+------------+--------------+------------+--------------------+--------------------+----------+----------+------------+------------+-------------+--------+----+---------+\n",
      "|    cik|accession_number_int|filing_date|datapoint_id|datapoint_name|     version|       segment_label|        segment_hash|start_date|  end_date|period_month|string_value|numeric_value|decimals|unit|footnotes|\n",
      "+-------+--------------------+-----------+------------+--------------+------------+--------------------+--------------------+----------+----------+------------+------------+-------------+--------+----+---------+\n",
      "| 885639|     156459019009005| 2019-03-22|  1082251202| NetIncomeLoss|us-gaap/2018|                  \\N|                  \\N|2018-02-04|2018-05-05|           3|    75000000|        7.5E7|      -6| USD|       \\N|\n",
      "|1572758|     157275813000011| 2013-11-13|   239064150| NetIncomeLoss|us-gaap/2013|                  \\N|                  \\N|2013-02-27|2013-09-30|           7|      -18417|     -18417.0|       0| USD|       \\N|\n",
      "|1059131|     119312514043282| 2014-02-10|   269316027| NetIncomeLoss|us-gaap/2013|                  \\N|                  \\N|2012-10-01|2012-12-31|           3|     8317000|    8317000.0|      -3| USD|       \\N|\n",
      "|1559053|     155905313000010| 2013-11-12|   225364903| NetIncomeLoss|us-gaap/2013|                  \\N|                  \\N|2012-07-01|2012-09-30|           3|    -8668000|   -8668000.0|      -3| USD|       \\N|\n",
      "| 930803|     114420413028609| 2013-05-14|   149415843| NetIncomeLoss|us-gaap/2012|                  \\N|                  \\N|2011-10-01|2012-03-31|           6|       96751|      96751.0|       0| USD|       \\N|\n",
      "| 730464|     114420415052225| 2015-08-27|   599714197| NetIncomeLoss|us-gaap/2015|                  \\N|                  \\N|2014-07-01|2014-09-30|           3|    20440000|      2.044E7|      -3| USD|       \\N|\n",
      "| 788784|      78878419000028| 2019-07-31|  1128627075| NetIncomeLoss|us-gaap/2019|Operating Segment...|3b4164f3-4d9f-5a2...|2019-01-01|2019-06-30|           6|   256000000|       2.56E8|      -6| USD|       \\N|\n",
      "| 788784|      78878419000028| 2019-07-31|  1128624612| NetIncomeLoss|us-gaap/2019|         PSEG Power |38ee71c4-adbb-9c2...|2018-04-01|2018-06-30|           3|    41000000|        4.1E7|      -6| USD|       \\N|\n",
      "| 788784|      78878419000028| 2019-07-31|  1128627297| NetIncomeLoss|us-gaap/2019|Guarantor Subsidi...|45fb20ce-d9e6-dde...|2019-01-01|2019-06-30|           6|   286000000|       2.86E8|      -6| USD|       \\N|\n",
      "|1594805|     159480519000010| 2019-02-12|  1047181592| NetIncomeLoss|us-gaap/2018|                  \\N|                  \\N|2018-01-01|2018-12-31|          12|   -64553000|    -6.4553E7|      -3| USD|       \\N|\n",
      "|1489644|     149315212001260| 2012-09-12|    65752508| NetIncomeLoss|us-gaap/2012|                  \\N|                  \\N|2011-05-01|2011-07-31|           3|       -6350|      -6350.0|       0| USD|       \\N|\n",
      "|1362703|     106299312000172| 2012-01-17|   465216551| NetIncomeLoss|us-gaap/2011|                  \\N|                  \\N|2010-09-01|2010-11-30|           3|     -301241|    -301241.0|       0| USD|       \\N|\n",
      "| 930803|     114420413028609| 2013-05-14|   149415842| NetIncomeLoss|us-gaap/2012|                  \\N|                  \\N|2012-01-01|2012-03-31|           3|     -347181|    -347181.0|       0| USD|       \\N|\n",
      "|1079282|     155479513000418| 2013-07-31|   169408766| NetIncomeLoss|us-gaap/2013|                  \\N|                  \\N|2009-10-01|2009-12-31|           3|     -395848|    -395848.0|       0| USD|       \\N|\n",
      "|1649338|     164933818000027| 2018-03-15|   940154347| NetIncomeLoss|us-gaap/2016|                  \\N|                  \\N|2016-10-31|2017-01-29|           3|   239000000|       2.39E8|      -6| USD|       \\N|\n",
      "|1333274|     119312512335017| 2012-08-03|    48267474| NetIncomeLoss|us-gaap/2012|       Eliminations |e0abcf5c-eef9-f36...|2011-04-01|2011-06-30|           3|           0|          0.0|      -3| EUR|       \\N|\n",
      "|1333274|     119312512335017| 2012-08-03|    48267482| NetIncomeLoss|us-gaap/2012|       Eliminations |e0abcf5c-eef9-f36...|2012-04-01|2012-06-30|           3|           0|          0.0|      -3| EUR|       \\N|\n",
      "|1082198|     110465911046573| 2011-08-12|   115000308| NetIncomeLoss|us-gaap/2011|                  \\N|                  \\N|2011-01-01|2011-06-30|           6|      322785|     322785.0|       0| USD|       \\N|\n",
      "|1344736|     144586612000666| 2012-08-20|    56772202| NetIncomeLoss|us-gaap/2012|                  \\N|                  \\N|2009-01-01|2012-06-30|          42|    -2455294|   -2455294.0|      \\N| USD|       \\N|\n",
      "|1532930|     153293015000081| 2015-07-29|   570008081| NetIncomeLoss|us-gaap/2015|       Common Stock |a6a13d2c-1456-d80...|2015-01-01|2015-06-30|           6|           0|          0.0|      -3| USD|       \\N|\n",
      "+-------+--------------------+-----------+------------+--------------+------------+--------------------+--------------------+----------+----------+------------+------------+-------------+--------+----+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NIL = spark.sql('''\n",
    "    SELECT *\n",
    "    FROM data_point as c\n",
    "    Where datapoint_name =='NetIncomeLoss'\n",
    "    limit 100\n",
    "''')\n",
    "NIL.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-----------+------------+--------------------+------------+--------------------+--------------------+----------+----------+------------+------------+-------------+--------+------+---------+\n",
      "|    cik|accession_number_int|filing_date|datapoint_id|      datapoint_name|     version|       segment_label|        segment_hash|start_date|  end_date|period_month|string_value|numeric_value|decimals|  unit|footnotes|\n",
      "+-------+--------------------+-----------+------------+--------------------+------------+--------------------+--------------------+----------+----------+------------+------------+-------------+--------+------+---------+\n",
      "| 885639|     156459019009005| 2019-03-22|  1082251202|       NetIncomeLoss|us-gaap/2018|                  \\N|                  \\N|2018-02-04|2018-05-05|           3|    75000000|        7.5E7|      -6|   USD|       \\N|\n",
      "|1572758|     157275813000011| 2013-11-13|   239064150|       NetIncomeLoss|us-gaap/2013|                  \\N|                  \\N|2013-02-27|2013-09-30|           7|      -18417|     -18417.0|       0|   USD|       \\N|\n",
      "|1467845|     147793215005163| 2015-08-14|   581850635|                Cash|us-gaap/2014|                  \\N|                  \\N|        \\N|2015-04-30|          \\N|        2720|       2720.0|       0|   USD|       \\N|\n",
      "|1059131|     119312514043282| 2014-02-10|   269316027|       NetIncomeLoss|us-gaap/2013|                  \\N|                  \\N|2012-10-01|2012-12-31|           3|     8317000|    8317000.0|      -3|   USD|       \\N|\n",
      "|1559053|     155905313000010| 2013-11-12|   225364903|       NetIncomeLoss|us-gaap/2013|                  \\N|                  \\N|2012-07-01|2012-09-30|           3|    -8668000|   -8668000.0|      -3|   USD|       \\N|\n",
      "| 930803|     114420413028609| 2013-05-14|   149415843|       NetIncomeLoss|us-gaap/2012|                  \\N|                  \\N|2011-10-01|2012-03-31|           6|       96751|      96751.0|       0|   USD|       \\N|\n",
      "| 730464|     114420415052225| 2015-08-27|   599714197|       NetIncomeLoss|us-gaap/2015|                  \\N|                  \\N|2014-07-01|2014-09-30|           3|    20440000|      2.044E7|      -3|   USD|       \\N|\n",
      "| 788784|      78878419000028| 2019-07-31|  1128627075|       NetIncomeLoss|us-gaap/2019|Operating Segment...|3b4164f3-4d9f-5a2...|2019-01-01|2019-06-30|           6|   256000000|       2.56E8|      -6|   USD|       \\N|\n",
      "| 788784|      78878419000028| 2019-07-31|  1128624612|       NetIncomeLoss|us-gaap/2019|         PSEG Power |38ee71c4-adbb-9c2...|2018-04-01|2018-06-30|           3|    41000000|        4.1E7|      -6|   USD|       \\N|\n",
      "| 788784|      78878419000028| 2019-07-31|  1128627297|       NetIncomeLoss|us-gaap/2019|Guarantor Subsidi...|45fb20ce-d9e6-dde...|2019-01-01|2019-06-30|           6|   286000000|       2.86E8|      -6|   USD|       \\N|\n",
      "|1594805|     159480519000010| 2019-02-12|  1047181592|       NetIncomeLoss|us-gaap/2018|                  \\N|                  \\N|2018-01-01|2018-12-31|          12|   -64553000|    -6.4553E7|      -3|   USD|       \\N|\n",
      "| 903129|     156459019026397| 2019-07-26|  1127318862|WeightedAverageNu...|us-gaap/2018|                  \\N|                  \\N|2019-01-01|2019-06-30|           6|    33508000|     3.3508E7|      -3|shares|       \\N|\n",
      "|1489644|     149315212001260| 2012-09-12|    65752508|       NetIncomeLoss|us-gaap/2012|                  \\N|                  \\N|2011-05-01|2011-07-31|           3|       -6350|      -6350.0|       0|   USD|       \\N|\n",
      "|1362703|     106299312000172| 2012-01-17|   465216551|       NetIncomeLoss|us-gaap/2011|                  \\N|                  \\N|2010-09-01|2010-11-30|           3|     -301241|    -301241.0|       0|   USD|       \\N|\n",
      "| 930803|     114420413028609| 2013-05-14|   149415842|       NetIncomeLoss|us-gaap/2012|                  \\N|                  \\N|2012-01-01|2012-03-31|           3|     -347181|    -347181.0|       0|   USD|       \\N|\n",
      "|1079282|     155479513000418| 2013-07-31|   169408766|       NetIncomeLoss|us-gaap/2013|                  \\N|                  \\N|2009-10-01|2009-12-31|           3|     -395848|    -395848.0|       0|   USD|       \\N|\n",
      "|1649338|     164933818000027| 2018-03-15|   940154347|       NetIncomeLoss|us-gaap/2016|                  \\N|                  \\N|2016-10-31|2017-01-29|           3|   239000000|       2.39E8|      -6|   USD|       \\N|\n",
      "|1649338|     164933818000027| 2018-03-15|   940154775|WeightedAverageNu...|us-gaap/2016|                  \\N|                  \\N|2016-10-31|2017-01-29|           3|   399000000|       3.99E8|      -6|shares|       \\N|\n",
      "|1333274|     119312512335017| 2012-08-03|    48267474|       NetIncomeLoss|us-gaap/2012|       Eliminations |e0abcf5c-eef9-f36...|2011-04-01|2011-06-30|           3|           0|          0.0|      -3|   EUR|       \\N|\n",
      "|1333274|     119312512335017| 2012-08-03|    48267482|       NetIncomeLoss|us-gaap/2012|       Eliminations |e0abcf5c-eef9-f36...|2012-04-01|2012-06-30|           3|           0|          0.0|      -3|   EUR|       \\N|\n",
      "+-------+--------------------+-----------+------------+--------------------+------------+--------------------+--------------------+----------+----------+------------+------------+-------------+--------+------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SelectedDF = spark.sql('''\n",
    "    SELECT *\n",
    "    FROM data_point as c\n",
    "    Where datapoint_name in ('NetIncomeLoss','WeightedAverageNumberOfSharesOutstandingBasic','Cash')\n",
    "    limit 1000\n",
    "''')\n",
    "SelectedDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-aa14dd7f6605>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mWHERE\u001b[0m \u001b[0maccession_number_int\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;34m'164933818000027'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m ''')\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    378\u001b[0m         \"\"\"\n\u001b[1;32m    379\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1257\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "SelectedDF.createOrReplaceTempView('SelectedDF')\n",
    "test = spark.sql('''\n",
    "    SELECT *\n",
    "    FROM SelectedDF\n",
    "    WHERE accession_number_int =='164933818000027'\n",
    "''')\n",
    "test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SelectedDF' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-d2f086712d33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mSelectedDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'SelectedDF' is not defined"
     ]
    }
   ],
   "source": [
    "SelectedDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-6cd3c82b9dd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m transDF = SelectedDF.groupby(\"cid\", \"accession_number_int\",\"filing_date\",\"version\",\"segment_label\",\"segment_hash\",\n\u001b[1;32m      2\u001b[0m                              \"start_date\",\"end_date\",\"period_month\")\\\n\u001b[0;32m----> 3\u001b[0;31m                     \u001b[0;34m.\u001b[0m\u001b[0mpivot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"datapoint_name\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m                     \u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"numeric_value\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtransDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/sql/group.py\u001b[0m in \u001b[0;36mpivot\u001b[0;34m(self, pivot_col, values)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \"\"\"\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             \u001b[0mjgd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jgd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpivot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpivot_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0mjgd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jgd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpivot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpivot_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1257\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "transDF = SelectedDF.groupby(\"cid\", \"accession_number_int\",\"filing_date\",\"version\",\"segment_label\",\"segment_hash\",\n",
    "                             \"start_date\",\"end_date\",\"period_month\")\\\n",
    "                    .pivot(\"datapoint_name\")\\\n",
    "                    .agg(\"numeric_value\")\n",
    "transDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SelectedDF1 = spark.sql('''\n",
    "    SELECT *\n",
    "    FROM data_point as c\n",
    "    Where datapoint_name in ('CashAndCashEquivalentsAtCarryingValue', 'NetIncomeLoss', 'OperatingIncomeLoss', 'Revenues', 'SalesRevenueNet ', 'CostOfRevenue ', 'EarningsPerShareBasic', 'EarningsPerShareDiluted', 'NetCashProvidedByUsedInOperatingActivities', 'NetCashProvidedByUsedInFinancingActivities', 'NetCashProvidedByUsedInInvestingActivities', 'NetCashProvidedByUsedInOperatingActivitiesContinuingOperations', 'NetCashProvidedByUsedInFinancingActivitiesContinuingOperations', 'NetCashProvidedByUsedInInvestingActivitiesContinuingOperations', 'ShareBasedCompensation', 'PaymentsToAcquirePropertyPlantAndEquipment', 'OperatingExpenses', 'GeneralAndAdministrativeExpense', 'SellingGeneralAndAdministrativeExpense ', 'SellingAndMarketingExpense', 'IncomeTaxesPaid', 'ResearchAndDevelopmentExpense ****', 'PaymentsForRepurchaseOfCommonStock', 'CostOfGoodsSold', 'CostOfGoodsAndServicesSold', 'CostOfServices', 'RepaymentsOfLongTermDebt', 'PaymentsToAcquireBusinessesNetOfCashAcquired', 'PaymentsOfDividendsCommonStock', 'PaymentsOfDividends', 'LaborAndRelatedExpense', 'PaymentsOfFinancingCosts', 'IncreaseDecreaseInAccountsReceivable', 'AccountsReceivableNetCurrent', 'IncreaseDecreaseInInventories', 'IncreaseDecreaseInAccruedLiabilities', 'IncreaseDecreaseInAccountsPayable', 'LiabilitiesCurrent', 'Liabilities', 'AccountsPayableCurrent', 'StockholdersEquity', 'Assets', 'AssetsCurrent', 'GainLossOnDispositionOfAssets', 'CommonStockValue', 'PreferredStockValue', 'Goodwill', 'PropertyPlantAndEquipmentNet')\n",
    "''')\n",
    "SelectedDF1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Datasets Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "requirment\n",
    "Explore, assess and visualize the data. \n",
    "Aggregate, count, and summarize. \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## Read in\n",
    "## parse or reformat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#one by one explore, \n",
    "#e.g. for company_submission, print the year range, how many company submitted, the table of doc_type & frequency\n",
    "\n",
    "#select subsets and join them together\n",
    "#e.g. table#3&4, data points and report_presentation_line_item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## redundancy regarding to the data points\n",
    "## count nulls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## Provide potential next steps, \n",
    "## e.g. what relationship can be illustrated in the plot, for example the #of companies against yr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
